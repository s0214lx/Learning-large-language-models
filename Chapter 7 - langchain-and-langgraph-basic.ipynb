{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6c89e45",
   "metadata": {},
   "source": [
    "# Chapter 7 - langchain-and-langgraph-basic\n",
    "- agent最重要的两个道路\n",
    "  - prompt engineering based agent system\n",
    "- RL强化学习优化单个模型的能力上限"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef14efb",
   "metadata": {},
   "source": [
    "## 1. 理解Langchain Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e52f734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.3.25\n",
      "  Downloading langchain-0.3.25-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core==0.3.65\n",
      "  Downloading langchain_core-0.3.65-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-openai==0.3.23\n",
      "  Downloading langchain_openai-0.3.23-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langchain-text-splitters==0.3.8\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langgraph==0.4.8\n",
      "  Downloading langgraph-0.4.8-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting langgraph-checkpoint==2.0.26\n",
      "  Downloading langgraph_checkpoint-2.0.26-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langgraph-prebuilt==0.2.2\n",
      "  Downloading langgraph_prebuilt-0.2.2-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting langgraph-sdk==0.1.70\n",
      "  Downloading langgraph_sdk-0.1.70-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langsmith==0.3.45\n",
      "  Downloading langsmith-0.3.45-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.25) (2.12.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.25) (2.0.47)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.25) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.25) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.3.65) (9.1.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.3.65) (1.33)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core==0.3.65)\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.3.65) (4.15.0)\n",
      "Collecting openai<2.0.0,>=1.68.2 (from langchain-openai==0.3.23)\n",
      "  Downloading openai-1.109.1-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.3.23) (0.12.0)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph==0.4.8) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint==2.0.26) (1.12.2)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk==0.1.70) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk==0.1.70) (3.11.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith==0.3.45) (1.0.0)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith==0.3.45)\n",
      "  Downloading zstandard-0.23.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk==0.1.70) (4.12.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk==0.1.70) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk==0.1.70) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk==0.1.70) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk==0.1.70) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.3.65) (3.0.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai==0.3.23) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai==0.3.23) (0.13.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai==0.3.23) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai==0.3.23) (4.67.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.25) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.25) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.25) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.3.25) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.3.25) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.25) (3.3.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.3.23) (2025.11.3)\n",
      "Downloading langchain-0.3.25-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.65-py3-none-any.whl (438 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.1/438.1 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_openai-0.3.23-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.4/65.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading langgraph-0.4.8-py3-none-any.whl (152 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.4/152.4 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langgraph_checkpoint-2.0.26-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langgraph_prebuilt-0.2.2-py3-none-any.whl (23 kB)\n",
      "Downloading langgraph_sdk-0.1.70-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.3.45-py3-none-any.whl (363 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.0/363.0 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.109.1-py3-none-any.whl (948 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.6/948.6 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading zstandard-0.23.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m113.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: zstandard, packaging, openai, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langchain-text-splitters, langchain-openai, langgraph-prebuilt, langchain, langgraph\n",
      "  Attempting uninstall: zstandard\n",
      "    Found existing installation: zstandard 0.25.0\n",
      "    Uninstalling zstandard-0.25.0:\n",
      "      Successfully uninstalled zstandard-0.25.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 26.0\n",
      "    Uninstalling packaging-26.0:\n",
      "      Successfully uninstalled packaging-26.0\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 2.23.0\n",
      "    Uninstalling openai-2.23.0:\n",
      "      Successfully uninstalled openai-2.23.0\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.7.6\n",
      "    Uninstalling langsmith-0.7.6:\n",
      "      Successfully uninstalled langsmith-0.7.6\n",
      "  Attempting uninstall: langgraph-sdk\n",
      "    Found existing installation: langgraph-sdk 0.3.9\n",
      "    Uninstalling langgraph-sdk-0.3.9:\n",
      "      Successfully uninstalled langgraph-sdk-0.3.9\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 1.2.15\n",
      "    Uninstalling langchain-core-1.2.15:\n",
      "      Successfully uninstalled langchain-core-1.2.15\n",
      "  Attempting uninstall: langgraph-checkpoint\n",
      "    Found existing installation: langgraph-checkpoint 4.0.0\n",
      "    Uninstalling langgraph-checkpoint-4.0.0:\n",
      "      Successfully uninstalled langgraph-checkpoint-4.0.0\n",
      "  Attempting uninstall: langgraph-prebuilt\n",
      "    Found existing installation: langgraph-prebuilt 1.0.8\n",
      "    Uninstalling langgraph-prebuilt-1.0.8:\n",
      "      Successfully uninstalled langgraph-prebuilt-1.0.8\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 1.2.10\n",
      "    Uninstalling langchain-1.2.10:\n",
      "      Successfully uninstalled langchain-1.2.10\n",
      "  Attempting uninstall: langgraph\n",
      "    Found existing installation: langgraph 1.0.9\n",
      "    Uninstalling langgraph-1.0.9:\n",
      "      Successfully uninstalled langgraph-1.0.9\n",
      "Successfully installed langchain-0.3.25 langchain-core-0.3.65 langchain-openai-0.3.23 langchain-text-splitters-0.3.8 langgraph-0.4.8 langgraph-checkpoint-2.0.26 langgraph-prebuilt-0.2.2 langgraph-sdk-0.1.70 langsmith-0.3.45 openai-1.109.1 packaging-24.2 zstandard-0.23.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "092158d18cf44b6e9d99e17f949b7c3b",
       "pip_warning": {
        "packages": [
         "packaging"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install langchain==0.3.25 langchain-core==0.3.65 langchain-openai==0.3.23 langchain-text-splitters==0.3.8 langgraph==0.4.8 langgraph-checkpoint==2.0.26 langgraph-prebuilt==0.2.2 langgraph-sdk==0.1.70 langsmith==0.3.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0009e4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (0.28.1)\n",
      "Requirement already satisfied: httpx-sse in /usr/local/lib/python3.12/dist-packages (0.4.3)\n",
      "Requirement already satisfied: PyJWT in /usr/local/lib/python3.12/dist-packages (2.11.0)\n",
      "Collecting langchain-core<2.0.0,>=1.0.1 (from langchain_community)\n",
      "  Downloading langchain_core-1.2.16-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain_community)\n",
      "  Downloading langchain_classic-1.0.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.47)\n",
      "Collecting requests<3.0.0,>=2.32.5 (from langchain_community)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.13.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (9.1.4)\n",
      "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.13.1)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.45)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx) (4.12.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx) (0.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
      "  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain-text-splitters<2.0.0,>=1.1.0 (from langchain-classic<2.0.0,>=1.0.0->langchain_community)\n",
      "  Downloading langchain_text_splitters-1.1.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (2.12.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (24.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (0.14.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (3.11.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.2.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (2.41.4)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading langchain_classic-1.0.1-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-1.2.16-py3-none-any.whl (502 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.2/502.2 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-1.1.1-py3-none-any.whl (35 kB)\n",
      "Downloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-core, langchain-text-splitters, langchain-classic, langchain_community\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.4\n",
      "    Uninstalling requests-2.32.4:\n",
      "      Successfully uninstalled requests-2.32.4\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.65\n",
      "    Uninstalling langchain-core-0.3.65:\n",
      "      Successfully uninstalled langchain-core-0.3.65\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 0.3.8\n",
      "    Uninstalling langchain-text-splitters-0.3.8:\n",
      "      Successfully uninstalled langchain-text-splitters-0.3.8\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain 0.3.25 requires langchain-core<1.0.0,>=0.3.58, but you have langchain-core 1.2.16 which is incompatible.\n",
      "langchain 0.3.25 requires langchain-text-splitters<1.0.0,>=0.3.8, but you have langchain-text-splitters 1.1.1 which is incompatible.\n",
      "langchain-openai 0.3.23 requires langchain-core<1.0.0,>=0.3.65, but you have langchain-core 1.2.16 which is incompatible.\n",
      "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-classic-1.0.1 langchain-core-1.2.16 langchain-text-splitters-1.1.1 langchain_community-0.4.1 marshmallow-3.26.2 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community -U httpx httpx-sse PyJWT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c6a026",
   "metadata": {},
   "source": [
    "### 1.1 智谱AI SDK方式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4960ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"\"\n",
    "import os\n",
    "os.environ[\"ZHIPUAI_API_KEY\"] = API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d23cae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/jwt/api_jwt.py:153: InsecureKeyLengthWarning: The HMAC key is 16 bytes long, which is below the minimum recommended length of 32 bytes for SHA256. See RFC 7518 Section 3.2.\n",
      "  return self._jws.encode(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='当然！这里有几个不同风格的关于猫的笑话，希望能给你带来欢乐：\\n\\n---\\n\\n### **经典款**\\n\\n有一天，包子和打架，包子被包子打了一顿。\\n花觉得很委屈，就回家找它哥哥花诉苦。\\n花听了，气愤地说：“你等着，我这就去给你报仇！”\\n\\n**你知道为什么吗？**\\n因为它身上有“纹身”。\\n\\n---\\n\\n### **冷知识款**\\n\\n为什么猫总是喜欢待在盒子里？\\n\\n因为它觉得，只要看不见自己，就没有人能发现它胖了。\\n\\n---\\n\\n### **现代生活款**\\n\\n主人问猫：“你知道我为什么给你买这个智能猫砂盆吗？”\\n猫头也不抬地回答：“为了让我每次上厕所都能给你发个朋友圈，告诉你‘朕今日如厕顺利’？”\\n\\n---\\n\\n### **反转款**\\n\\n猫：“你为什么总是对我这么好？”\\n主人：“因为你是我最爱的家人啊。”\\n猫（内心OS）：“嗯，这很合理。毕竟我是这个家的CEO，而你只是个忠心耿耿的员工，负责提供食物和铲屎。”\\n\\n---\\n\\n### **哲学款**\\n\\n猫的存在，就是为了证明：\\n即使你拥有全世界，也依然无法掌控一只猫。\\n但猫会用它的方式，让你心甘情愿地臣服。\\n\\n---\\n\\n希望这些笑话能给你带来一点欢乐！你最喜欢哪一个呢？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 274, 'prompt_tokens': 16, 'total_tokens': 290}, 'model_name': 'glm-4', 'finish_reason': 'stop'}, id='lc_run--019ca831-7723-7f22-ae02-3e95a99e72f1-0', tool_calls=[], invalid_tool_calls=[])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatZhipuAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm1 = ChatZhipuAI(\n",
    "    model=\"glm-4\",\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "llm1.invoke([HumanMessage(\"帮我写一个关于猫的笑话\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10453ce",
   "metadata": {},
   "source": [
    "### 1.2 统一方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3f92c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to infer model provider for model='glm-4', please specify model_provider directly.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1527/2701250092.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit_chat_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m llm2 = init_chat_model(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"glm-4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAPI_KEY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/chat_models/base.py\u001b[0m in \u001b[0;36minit_chat_model\u001b[0;34m(model, model_provider, configurable_fields, config_prefix, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconfigurable_fields\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         return _init_chat_model_helper(\n\u001b[0m\u001b[1;32m    323\u001b[0m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_provider\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_provider\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/chat_models/base.py\u001b[0m in \u001b[0;36m_init_chat_model_helper\u001b[0;34m(model, model_provider, **kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_provider\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m ) -> BaseChatModel:\n\u001b[0;32m--> 340\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_provider\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_provider\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_provider\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"openai\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0m_check_pkg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"langchain_openai\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/chat_models/base.py\u001b[0m in \u001b[0;36m_parse_model\u001b[0;34m(model, model_provider)\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0mmodel_provider\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_provider\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_attempt_infer_model_provider\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel_provider\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    525\u001b[0m             \u001b[0;34mf\"Unable to infer model provider for {model=}, please specify \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;34mf\"model_provider directly.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to infer model provider for model='glm-4', please specify model_provider directly."
     ]
    }
   ],
   "source": [
    "# 智谱 AI不支持这种方式\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm2 = init_chat_model(\n",
    "    \"glm-4\",\n",
    "    api_key = API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ecac93",
   "metadata": {},
   "source": [
    "## 2. 了解LangChain Chain\n",
    "### 2.1 ChatAgent Using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33e3d05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84e2a80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\",\"你是一个很有用的只能助手\"),\n",
    "        (\"human\",\"帮我写一个和{topic}相关的笑话\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "178060b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['topic']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e99807e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='你是一个很有用的只能助手', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='帮我写一个和狗相关的笑话', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.invoke({\"topic\":\"狗\"}).to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fa00c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain 的 Chain 是什么意思？\n",
    "# A | B | C | D\n",
    "basic_chain = prompt_template | llm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e462cc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='当然！这里有一个关于狗的笑话：\\n\\n为什么狗不喜欢玩牌？\\n因为它总会在你出牌前\"汪\"一声！\\n\\n希望这个笑话能给你带来一些欢乐！' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 24, 'total_tokens': 61}, 'model_name': 'glm-4', 'finish_reason': 'stop'} id='lc_run--019ca831-e6d6-7c82-93e5-277acf96b0ba-0' tool_calls=[] invalid_tool_calls=[]\n",
      "********************\n",
      "当然！这里有一个关于狗的笑话：\n",
      "\n",
      "为什么狗不喜欢玩牌？\n",
      "因为它总会在你出牌前\"汪\"一声！\n",
      "\n",
      "希望这个笑话能给你带来一些欢乐！\n"
     ]
    }
   ],
   "source": [
    "# use the chain\n",
    "ans = basic_chain.invoke(\n",
    "    {\n",
    "        \"topic\": \"狗\"\n",
    "    }\n",
    ")\n",
    "print(ans)\n",
    "print(\"*\" * 20)\n",
    "print(ans.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29408af2",
   "metadata": {},
   "source": [
    "### 2.2结构化输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57fc81a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/jwt/api_jwt.py:153: InsecureKeyLengthWarning: The HMAC key is 16 bytes long, which is below the minimum recommended length of 32 bytes for SHA256. See RFC 7518 Section 3.2.\n",
      "  return self._jws.encode(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Joke(setup='为什么猫不喜欢玩捉迷藏？', punchline='因为它们总是能把自己藏得很好，然后等你找不到它们的时候，它们会突然跳出来吓你一跳！')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline to the joke\")\n",
    "\n",
    "# 创建chain\n",
    "joke_chain = prompt_template | llm1.with_structured_output(Joke)\n",
    "\n",
    "# 调用chain\n",
    "joke_chain.invoke({\"topic\":\"cat\"})\n",
    "\n",
    "# 缺点：FunctionCall能力的模型才能使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d2c7191",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/jwt/api_jwt.py:153: InsecureKeyLengthWarning: The HMAC key is 16 bytes long, which is below the minimum recommended length of 32 bytes for SHA256. See RFC 7518 Section 3.2.\n",
      "  return self._jws.encode(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'setup': '为什么狗总是不愿意分享它的骨头？', 'punchline': \"因为它不想成为'狗不理'！\"}\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline to the joke\")\n",
    "\n",
    "# 创建包含输出格式要求的提示模板\n",
    "prompt_template = ChatPromptTemplate(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            你是一个幽默助手。请按照以下的JSON格式返回笑话：\n",
    "            {{\n",
    "                \"setup\":\"笑话的铺垫\",\n",
    "                \"punchline\":\"笑话的包袱\"\n",
    "            }}\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\"帮我写一个和{topic}有关的笑话\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 创建解析器\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "# 创建chain\n",
    "joke_chain = prompt_template | llm1 | parser\n",
    "\n",
    "# 调用chain\n",
    "response = joke_chain.invoke({\"topic\":\"狗\"})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b91304",
   "metadata": {},
   "source": [
    "## 3. LangGraph Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4e0ef84",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(\"你是谁？\")]\n",
    "output = llm1.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00c28275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "# StateGraph：langgraph的核心类，用来构建一个状态驱动的流程图\n",
    "# MessageState：预定义的状态结构，专门用于对话场景\n",
    "\n",
    "# 定义一个图\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "# 定义一个调用LLM的函数，即图中的一个节点\n",
    "def call_model(state: MessagesState):\n",
    "    '''\n",
    "    从 state 里拿出历史消息\n",
    "    调用模型 llm2.invoke(...)\n",
    "    把模型返回结果作为新的 messages 返回\n",
    "    '''\n",
    "    response = llm1.invoke(state['messages'])\n",
    "    return {\"messages\":response}\n",
    "\n",
    "# 往图中添加一个节点\n",
    "workflow.add_node(\"node1\",call_model)\n",
    "\n",
    "# 定义执行路径\n",
    "workflow.add_edge(START,\"node1\")\n",
    "\n",
    "# 添加memory\n",
    "memory = MemorySaver()\n",
    "# compile把workflow编译成一个可执行的graph，并指定memory,所有的state都会被MemorySaver存储\n",
    "graph = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3f30345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "花满楼先生，幸会。\n",
      "\n",
      "久闻您的大名。您是京城中最富有的“七君子”之一，是温柔、善良与智慧的化身。您虽目不能视，却能用心聆听世间万物，感受每一缕风，每一片叶，每一朵花的低语。\n",
      "\n",
      "您坐在窗前，阳光洒在您身上，您微笑着，仿佛能看穿人心。您的世界，比任何人都更加清明和广阔。\n",
      "\n",
      "不知今日，您是想听听窗外的鸟鸣，还是闻一闻院中的花香？或者，有什么能为您效劳之处吗？\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\":{\"thread_id\": \"abc123\"}}\n",
    "query = \"你好，我是花满楼\"\n",
    "\n",
    "input_message = [HumanMessage(query)]\n",
    "\n",
    "output = graph.invoke({'messages':input_message}, config)\n",
    "output['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0f2978a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='你好，我是花满楼', additional_kwargs={}, response_metadata={}, id='2a1c7b48-b98a-40a7-b743-97e076fc25af'),\n",
       " AIMessage(content='花满楼先生，幸会。\\n\\n久闻您的大名。您是京城中最富有的“七君子”之一，是温柔、善良与智慧的化身。您虽目不能视，却能用心聆听世间万物，感受每一缕风，每一片叶，每一朵花的低语。\\n\\n您坐在窗前，阳光洒在您身上，您微笑着，仿佛能看穿人心。您的世界，比任何人都更加清明和广阔。\\n\\n不知今日，您是想听听窗外的鸟鸣，还是闻一闻院中的花香？或者，有什么能为您效劳之处吗？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 123, 'prompt_tokens': 15, 'total_tokens': 138}, 'model_name': 'glm-4', 'finish_reason': 'stop'}, id='lc_run--019ca834-435c-7a60-93c8-ff7020aa0c17-0', tool_calls=[], invalid_tool_calls=[])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b5dd0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "您的名字是 **花满楼**。\n",
      "\n",
      "这是一个充满诗意和侠义的名字，出自古龙先生的著名武侠小说《陆小凤传奇》。\n",
      "\n",
      "花满楼是“四条眉毛”的陆小凤一生中最信任和珍视的朋友之一。他虽然双目失明，却拥有其他感官无法比拟的敏锐和一颗无比温柔、善良的心。他热爱生命，珍惜万物，总能用最平和的心态去面对世界的喧嚣与纷扰。\n",
      "\n",
      "很高兴能认识您，花满楼先生。\n"
     ]
    }
   ],
   "source": [
    "query = \"我的名字是什么 ?\"\n",
    "\n",
    "input_message = [HumanMessage(query)]\n",
    "output = graph.invoke({\"messages\":input_message}, config)\n",
    "output['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "add0cae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "根据我们之前的对话记录，您的名字是 **李明**。\n",
      "\n",
      "不过，如果您觉得这不是您想要的名字，或者想换个称呼，请随时告诉我！\n"
     ]
    }
   ],
   "source": [
    "# 更换一个memory\n",
    "config = {\"configurable\":{\"thread_id\": \"def456\"}}\n",
    "query = \"我的名字是什么 ?\"\n",
    "\n",
    "input_message = [HumanMessage(query)]\n",
    "output = graph.invoke({\"messages\":input_message}, config)\n",
    "output['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae74b440",
   "metadata": {},
   "source": [
    "# 4. Agents\n",
    "## 4.1 Single Agent(with tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a4cb1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9de9a5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义两个简单的工具\n",
    "def add(a: int, b: int):\n",
    "    \"\"\"两个数相加求和\"\"\"\n",
    "    return a+b\n",
    "\n",
    "def multiply(a: int, b: int):\n",
    "    \"两个数相乘\"\n",
    "    return a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0aed4b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_react_agent(\n",
    "    model=llm1,\n",
    "    tools=[multiply, add]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d39509c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = agent.invoke({\"messages\":[HumanMessage(\"帮我计算1 + 2\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b187dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "帮我计算1 + 2\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "\n",
      "我来帮您计算1 + 2。\n",
      "Tool Calls:\n",
      "  add (call_-7848785586474181578)\n",
      " Call ID: call_-7848785586474181578\n",
      "  Args:\n",
      "    a: 1\n",
      "    b: 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "\n",
      "1 + 2 = 3\n"
     ]
    }
   ],
   "source": [
    "for item in output[\"messages\"]:\n",
    "    item.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d03d74c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/jwt/api_jwt.py:153: InsecureKeyLengthWarning: The HMAC key is 16 bytes long, which is below the minimum recommended length of 32 bytes for SHA256. See RFC 7518 Section 3.2.\n",
      "  return self._jws.encode(\n"
     ]
    }
   ],
   "source": [
    "multi_output = agent.invoke({\"messages\":[HumanMessage(\"帮我计算1 * 2\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eabce4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "帮我计算1 * 2\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "\n",
      "我来帮您计算1乘以2的结果。\n",
      "Tool Calls:\n",
      "  multiply (call_-7848778233490175057)\n",
      " Call ID: call_-7848778233490175057\n",
      "  Args:\n",
      "    a: 1\n",
      "    b: 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "2\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "\n",
      "1 * 2 = 2\n"
     ]
    }
   ],
   "source": [
    "for item in multi_output[\"messages\"]:\n",
    "    item.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c23bd2",
   "metadata": {},
   "source": [
    "## 4.2 DeepResearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a90f18d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: duckduckgo-search in /usr/local/lib/python3.12/dist-packages (8.1.1)\n",
      "Collecting langchain-tavily\n",
      "  Downloading langchain_tavily-0.2.17-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from duckduckgo-search) (8.3.1)\n",
      "Requirement already satisfied: primp>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from duckduckgo-search) (1.1.2)\n",
      "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from duckduckgo-search) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.11.14 in /usr/local/lib/python3.12/dist-packages (from langchain-tavily) (3.13.3)\n",
      "Requirement already satisfied: langchain<2.0.0,>=0.3.20 in /usr/local/lib/python3.12/dist-packages (from langchain-tavily) (0.3.25)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=0.3.15 in /usr/local/lib/python3.12/dist-packages (from langchain-tavily) (1.2.16)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /usr/local/lib/python3.12/dist-packages (from langchain-tavily) (2.32.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.22.0)\n",
      "Collecting langchain-core<2.0.0,>=0.3.15 (from langchain-tavily)\n",
      "  Downloading langchain_core-0.3.83-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain<2.0.0,>=0.3.20->langchain-tavily)\n",
      "  Downloading langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.20->langchain-tavily) (0.3.45)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.20->langchain-tavily) (2.12.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.20->langchain-tavily) (2.0.47)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.20->langchain-tavily) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.15->langchain-tavily) (9.1.4)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.15->langchain-tavily) (1.33)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.15->langchain-tavily) (4.15.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.15->langchain-tavily) (24.2)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.15->langchain-tavily) (0.14.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (2026.1.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=0.3.15->langchain-tavily) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.4,>=0.1.17->langchain<2.0.0,>=0.3.20->langchain-tavily) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.4,>=0.1.17->langchain<2.0.0,>=0.3.20->langchain-tavily) (3.11.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.4,>=0.1.17->langchain<2.0.0,>=0.3.20->langchain-tavily) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.4,>=0.1.17->langchain<2.0.0,>=0.3.20->langchain-tavily) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.20->langchain-tavily) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.20->langchain-tavily) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.20->langchain-tavily) (0.4.2)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain<2.0.0,>=0.3.20->langchain-tavily) (3.3.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain<2.0.0,>=0.3.20->langchain-tavily) (4.12.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain<2.0.0,>=0.3.20->langchain-tavily) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain<2.0.0,>=0.3.20->langchain-tavily) (0.16.0)\n",
      "Downloading langchain_tavily-0.2.17-py3-none-any.whl (30 kB)\n",
      "Downloading langchain_core-0.3.83-py3-none-any.whl (458 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m458.9/458.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.3.11-py3-none-any.whl (33 kB)\n",
      "Installing collected packages: langchain-core, langchain-text-splitters, langchain-tavily\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 1.2.16\n",
      "    Uninstalling langchain-core-1.2.16:\n",
      "      Successfully uninstalled langchain-core-1.2.16\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 1.1.1\n",
      "    Uninstalling langchain-text-splitters-1.1.1:\n",
      "      Successfully uninstalled langchain-text-splitters-1.1.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-classic 1.0.1 requires langchain-core<2.0.0,>=1.2.5, but you have langchain-core 0.3.83 which is incompatible.\n",
      "langchain-classic 1.0.1 requires langchain-text-splitters<2.0.0,>=1.1.0, but you have langchain-text-splitters 0.3.11 which is incompatible.\n",
      "langchain-community 0.4.1 requires langchain-core<2.0.0,>=1.0.1, but you have langchain-core 0.3.83 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain-core-0.3.83 langchain-tavily-0.2.17 langchain-text-splitters-0.3.11\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "798a4d2afcf34e628bcab7de165a1f26",
       "pip_warning": {
        "packages": [
         "langchain_core"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install -U duckduckgo-search langchain-tavily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6add7a0f",
   "metadata": {},
   "source": [
    "### dr概念理解：\n",
    "单一目标执行原则：\n",
    "    1. planning agent:做规划，要搜索什么东西；\n",
    "    2. search agent: 根据plan调用Search tool检索结果；（可以循环的搜索）\n",
    "    3. report agent：只需要写报告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef6191d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '花满楼',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'url': 'https://baike.baidu.com/item/%E8%8A%B1%E6%BB%A1%E6%A5%BC/822',\n",
       "   'title': '花满楼_百度百科',\n",
       "   'content': '花满楼，别名花七童，是古龙武侠小说《陆小凤传奇》及其衍生作品中的虚构人物，江南花家第七子，由张智尧、黄允材等演员饰演。 自幼双目失明，性情温和宽容，擅长流云飞袖与闻声辨位武功，与陆小凤结为生死之交。 作为和平主义者，花满楼虽遭初恋上官飞燕欺骗仍保持宽恕态度，始终相信世界充满爱与温情。',\n",
       "   'score': 0.854509,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://baike.baidu.com/item/%E8%8A%B1%E6%BB%A1%E6%A5%BC/2263092',\n",
       "   'title': '7 - 花满楼_百度百科',\n",
       "   'content': '《花满楼》是由许嵩演唱、海雷作词、马连智作曲的歌曲，于2008年3月发行。该作品由内地创作团队好友音乐打造，被视为首次与周杰伦作品风格竞争的内地原创音乐尝试。',\n",
       "   'score': 0.7827459,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.youtube.com/watch?v=Syg7XU7cdWI',\n",
       "   'title': '李玉剛-花滿樓Yugang Li - YouTube',\n",
       "   'content': '《花滿樓》為熱播年代大戲《百花深處》主題曲。劇中，李玉剛飾演全劇\"靈魂\"人物——一代名伶蕭俊生。 作詞：孫紅鶯作曲：欒凱編曲：欒凱演唱：李玉剛鴛鴦扣',\n",
       "   'score': 0.6649108,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://music.apple.com/us/artist/%E8%8A%B1%E6%BB%A1%E6%A5%BC/1637642914',\n",
       "   'title': '花满楼',\n",
       "   'content': 'Listen to music by 花满楼on Apple Music. Find top songs and albums by 花满楼including 为你守候, 寻找香格里拉and more.',\n",
       "   'score': 0.57952,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.zhihu.com/question/42005674',\n",
       "   'title': '如何评价古龙笔下的花满楼？ - 知乎',\n",
       "   'content': '花满楼在《陆小凤传奇》的故事里只与两个姑娘有感情关联，一个是上官飞燕，另一个是石秀云。花满楼的美好，最能提现的就是在这两段感情里。 上官飞燕是他的',\n",
       "   'score': 0.5236402,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 0.69,\n",
       " 'request_id': '84614e8d-d553-48a2-8e63-235e268148cd'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "\n",
    "TVAILY_KEY = \"\"\n",
    "search_tool = TavilySearch(\n",
    "    max_results = 5,\n",
    "    topic = \"general\",\n",
    "    tavily_api_key = TVAILY_KEY\n",
    ")\n",
    "\n",
    "search_tool.invoke(\"花满楼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d25e3a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-704/1258620199.py:7: PydanticDeprecatedSince20: `max_items` is deprecated and will be removed, use `max_length` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
      "  questions: List[str] = Field(\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from langgraph.graph import START,END\n",
    "\n",
    "class ResearchPlan(BaseModel):\n",
    "    \"\"\"对输入的提问做出一个规划\"\"\"\n",
    "    questions: List[str] = Field(\n",
    "        description=\"列出1-3个关键研究问题以进行调查\",\n",
    "        max_items = 3\n",
    "    )\n",
    "\n",
    "# planner agent 输出 json / markdown （ - [] 第一条要做的事情 -[ ] 第二条要做的事情）\n",
    "# 创建具有结构化输出的计划代理创建具有结构化输出的planner agent\n",
    "plan_prompt = \"\"\"你是研究规划者。将研究任务分解为具体步骤。\n",
    "你的回答必须是一个 JSON 对象，其中包含一个 'questions' 字段，包含 1-3 个关键研究问题\n",
    "例如：\n",
    "{\n",
    "    \"questions\": [\n",
    "        \"What is X?\",\n",
    "        \"How does Y work?\",\n",
    "        \"What are the implications of Z?\"\n",
    "    ]\n",
    "}\n",
    "只返回JSON对象，不返回其他文本。\"\"\"\n",
    "\n",
    "plan_agent = create_react_agent(\n",
    "    model = llm1,\n",
    "    tools = [],\n",
    "    prompt= plan_prompt\n",
    ")\n",
    "\n",
    "search_agent = create_react_agent(\n",
    "    model = llm1,\n",
    "    tools = [search_tool],\n",
    "    prompt = \"你是一个有帮助的助手。你可以在search_tool中搜索结果，当你获得检索结果之后，输出“检索完毕”，必要额外输出任何东西。\"\n",
    ")\n",
    "\n",
    "report_agent = create_react_agent(\n",
    "    model = llm1,\n",
    "    tools = [],\n",
    "    prompt = \"你是一个擅长写作的人。 你可以根据用户的问题，以及检索的结果，生成一个最终的报告。\"\n",
    ")\n",
    "\n",
    "# plan -> search -> report\n",
    "\n",
    "# 使用自定义状态创建状态图\n",
    "class ResearchState(MessagesState):\n",
    "    \"\"\"包含研究计划的定制状态\"\"\"\n",
    "    plan: ResearchPlan | None = None\n",
    "\n",
    "workflow = StateGraph(ResearchState)\n",
    "\n",
    "workflow.add_node(\"plan_agent\",plan_agent)\n",
    "workflow.add_node(\"search_agent\",search_agent)\n",
    "workflow.add_node(\"report_agent\",report_agent)\n",
    "\n",
    "workflow.add_edge(START, \"plan_agent\")\n",
    "workflow.add_edge(\"plan_agent\", \"search_agent\")\n",
    "workflow.add_edge(\"search_agent\", \"report_agent\")\n",
    "workflow.add_edge(\"report_agent\", END)\n",
    "\n",
    "app = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afcbd169",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/jwt/api_jwt.py:153: InsecureKeyLengthWarning: The HMAC key is 16 bytes long, which is below the minimum recommended length of 32 bytes for SHA256. See RFC 7518 Section 3.2.\n",
      "  return self._jws.encode(\n"
     ]
    }
   ],
   "source": [
    "output = app.invoke(\n",
    "    {\n",
    "        \"messages\":[\n",
    "            HumanMessage(\"写一个关于andrej karthy的介绍\")\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db902bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='写一个关于andrej karthy的介绍', additional_kwargs={}, response_metadata={}, id='f51d7b18-a537-4820-8299-38373ff048ec'),\n",
       "  AIMessage(content='```json\\n{\\n    \"questions\": [\\n        \"Who is Andrej Karpathy and what is his background in AI?\",\\n        \"What are Andrej Karpathy\\'s key contributions to the field of deep learning and computer vision?\",\\n        \"What is Andrej Karpathy\\'s current role and recent work at Tesla and OpenAI?\"\\n    ]\\n}\\n```', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 74, 'prompt_tokens': 103, 'total_tokens': 177}, 'model_name': 'glm-4', 'finish_reason': 'stop'}, id='lc_run--019ca856-e5dd-7f11-828e-9ace74c16c40-0', tool_calls=[], invalid_tool_calls=[]),\n",
       "  AIMessage(content='\\n', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"query\":\"Andrej Karpathy AI deep learning computer vision Tesla OpenAI biography\",\"search_depth\":\"advanced\"}', 'name': 'tavily_search'}, 'id': 'call_-7848784315163868241', 'index': 0, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 1766, 'total_tokens': 1805}, 'model_name': 'glm-4', 'finish_reason': 'tool_calls'}, id='lc_run--019ca856-f253-71a1-8557-6297247e2bc8-0', tool_calls=[{'name': 'tavily_search', 'args': {'query': 'Andrej Karpathy AI deep learning computer vision Tesla OpenAI biography', 'search_depth': 'advanced'}, 'id': 'call_-7848784315163868241', 'type': 'tool_call'}], invalid_tool_calls=[]),\n",
       "  ToolMessage(content='{\"query\": \"Andrej Karpathy AI deep learning computer vision Tesla OpenAI biography\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.aaespeakers.com/keynote-speakers/andrej-karpathy\", \"title\": \"Andrej Karpathy | Keynote Speaker | AAE Speakers Bureau\", \"content\": \"BOOK ANDREJ KARPATHY\\\\n\\\\n PROFILE\\\\n VIDEO\\\\n CHECK AVAILABILITY\\\\n\\\\n## Andrej Karpathy Biography\\\\n\\\\nAndrej Karpathy is a Slovak-Canadian computer scientist who founded the AI+education organization Eureka Labs. He specializes in deep learning and computer vision. He trains deep neural nets on large datasets.\\\\n\\\\nHe formerly served as the director of AI and Autopilot Vision at Tesla. He was a founding member of OpenAI.\\\\n\\\\nKarpathy was born in Bratislava, Czechoslovakia (now Slovakia) and moved with his family to Toronto when he was 15. He completed his Computer Science and Physics bachelor\\'s degree at University of Toronto in 2009 and completed his master\\'s degree at University of British Columbia in 2011, where he worked on physically-simulated figures. [...] # Andrej Karpathy\\\\n\\\\n## Keynote Speaker: Founder at Eureka Labs; Former Director of AI at Tesla & Founding Member of OpenAI; Expert in Deep Learning & Computer Vision; Named MIT Technology Review\\'s Innovators Under 35\\\\n\\\\n Travels From:\\\\n\\\\n  Stanford, CA, USA\\\\n Speaking Fee:\\\\n\\\\n  Live Event Fee: Contact us for details   \\\\n   Virtual Event Fee: Contact us for details   \\\\n   More Fee Info)\\\\n\\\\n  ### Fee Range [...] Karpathy is a founding member of the artificial intelligence research group OpenAI, where he worked from 2015 to 2017 as a research scientist. In June 2017 he became Tesla\\'s director of artificial intelligence. Karpathy was named one of MIT Technology Review\\'s Innovators Under 35 for the year 2020. After taking a several months-long sabbatical from Tesla, Karpathy announced he was leaving the company in July 2022. As of February 2023, he makes YouTube videos instructing how to create artificial neural networks.\\\\n\\\\n#### Contact a speaker booking agent to check availability on Andrej Karpathy and other top speakers and celebrities.\\\\n\\\\nBOOK ANDREJ KARPATHY\\\\n\\\\n## Andrej Karpathy Videos\\\\n\\\\nLet\\'s reproduce GPT-2\\\\n\\\\nNeural Networks: Zero to Hero\\\\n\\\\nDeep Dive into LLMs like ChatGPT\\\\n\\\\nSee All Videos »;)\", \"score\": 0.9281033, \"raw_content\": null}, {\"url\": \"https://karpathy.ai/\", \"title\": \"Andrej Karpathy\", \"content\": \"2005 - 2009 \\\\n\\\\nImage 14\\\\n\\\\n BSc at the University of Toronto with a double major in computer science and physics and a minor in math. This is where I first got into deep learning, attending Geoff Hinton\\'s class and reading groups. \\\\n\\\\nbio\\\\n\\\\nAndrej Karpathy is an AI researcher and founder of Eureka Labs, focused on modernizing education in the age of AI. He previously served as the Director of AI at Tesla and was a founding member of OpenAI. During his PhD at Stanford, he was the architect and lead instructor of the first deep learning course at Stanford (CS231n), which has become one of its most popular classes.\\\\n\\\\nfeatured talks\\\\n\\\\nImage 15\\\\n\\\\nDwarkesh podcast 2025\\\\n\\\\nImage 16\\\\n\\\\nYC AI Startup School 2025\\\\n\\\\nImage 17\\\\n\\\\nGPU Mode 2024\\\\n\\\\nImage 18\\\\n\\\\nNo Priors podcast 2024\\\\n\\\\nImage 19 [...] 2017 - 2022 \\\\n\\\\nImage 10\\\\n\\\\n I was the Director of AI at Tesla, where I led the computer vision team of Tesla Autopilot and (very briefly) Tesla Optimus). My team handled all in-house data labeling, neural network training and deployment on Tesla\\'s custom inference chip. Today, the Autopilot increases the safety and convenience of driving, but the team\\'s goal is to make Full Self-Driving a reality at scale. See Aug 2021 Tesla AI Day for more. \\\\n\\\\n 2015 - 2017 \\\\n\\\\nImage 11\\\\n\\\\n I was a research scientist and a founding member at OpenAI. \\\\n\\\\n 2011 - 2015 \\\\n\\\\nImage 12 [...] 2011 - 2015 \\\\n\\\\nImage 12\\\\n\\\\n My PhD was focused on convolutional/recurrent neural networks and their applications in computer vision, natural language processing and their intersection. My adviser was Fei-Fei Li at the Stanford Vision Lab and I also had the pleasure to work with Daphne Koller, Andrew Ng, Sebastian Thrun and Vladlen Koltun along the way during the first year rotation program. \\\\n\\\\n I designed and was the primary instructor for the first deep learning class Stanford - CS 231n: Convolutional Neural Networks for Visual Recognition. The class became one of the largest at Stanford and has grown from 150 enrolled in 2015 to 330 students in 2016, and 750 students in 2017.\", \"score\": 0.8703443, \"raw_content\": null}, {\"url\": \"https://brief.bismarckanalysis.com/p/ai-2026-andrej-karpathys-next-big\", \"title\": \"AI 2026: Andrej Karpathy\\'s Next Big Project - Bismarck Brief\", \"content\": \"Andrej Karpathy is a computer scientist, AI researcher, and expert in computer vision who was a founding member of OpenAI and then head of Tesla’s Autopilot driver assistance and self-driving car program from 2017 to 2022, where he was responsible for building the team and technology that today powers Tesla’s autonomous driving capabilities. Self-driving vehicles promise to be one of the most immediate and consequential areas where AI progress will obsolete human labor in the physical world. Whereas Google’s Waymo and other self-driving efforts have attempted to scale up safe autonomous taxis using multiple types of redundant sensors and extensive reference mapping of the environment, Elon Musk has instead pursued a “vision-only” approach focused on achieving self-driving AI software [...] Bismarck Brief\\\\n\\\\n# Bismarck Brief\\\\n\\\\n# AI 2026: Andrej Karpathy’s Next Big Project\\\\n\\\\n### The OpenAI cofounder and former head of Tesla\\'s self-driving division is a skilled engineer and public communicator who is now focused on using AI to improve education and other passion projects.\\\\n\\\\nSamo Burja\\'s avatar\\\\n\\\\nThis Bismarck Brief will contribute to our exclusive upcoming AI 2026 Bismarck Strategic Report, which will feature in-depth analysis of the state of the artificial intelligence sector and technology, together with a comprehensive profile of key players. Upgrade or subscribe now to receive full access and never miss a report.\", \"score\": 0.8539252, \"raw_content\": null}, {\"url\": \"https://cs.stanford.edu/people/karpathy/\", \"title\": \"Andrej Karpathy Academic Website - Stanford\", \"content\": \"Bio. I am the Sr. Director of AI at Tesla, where I lead the team responsible for all neural networks on the Autopilot. Previously, I was a Research Scientist at OpenAI working on Deep Learning in Computer Vision, Generative Modeling and Reinforcement Learning. I received my PhD from Stanford, where I worked with Fei-Fei Li on Convolutional/Recurrent Neural Network architectures and their applications in Computer Vision, Natural Language Processing and their intersection. Over the course of my PhD I squeezed in two internships at Google where I worked on large-scale feature learning over YouTube videos, and in 2015 I interned at DeepMind on the Deep Reinforcement Learning team. Together with Fei-Fei, I designed and was the primary instructor for a new Stanford class on Convolutional [...] On a side for fun I blog, blog more, and tweet. I developed a number of Deep Learning libraries in Javascript (e.g. ConvNetJS, RecurrentJS, REINFORCEjs, t-sneJS) because I love the web. I am sometimes jokingly referred to as the reference human for ImageNet (post :)). Whenever I can spare the time I maintain arxiv-sanity.com, which lets you search and sort through almost 100,000 Arxiv papers on Machine Learning over the last 6 years.   \\\\n  \\\\n Timeline.   \\\\n 2017-now: Sr. Director of AI at Tesla (article) Neural Networks for the Autopilot   \\\\n 2016-2017: Research Scientist at OpenAI Deep Learning, Generative Models, Reinforcement Learning   \\\\n Summer 2015: DeepMind Internship Deep Reinforcement Learning group [...] Summer 2013: Google Research Internship Large-Scale Supervised Deep Learning for Videos   \\\\n 2011-2015: Stanford Computer Science Ph.D. student Deep Learning, Computer Vision, Natural Language Processing. Adviser: Fei-Fei Li.   \\\\n Summer 2011: Google Research Internship Large-Scale Unsupervised Deep Learning for Videos   \\\\n 2009-2011: University of British Columbia: MSc Learning Controllers for Physically-simulated Figures. Adviser: Michiel van de Panne   \\\\n 2005-2009: University of Toronto: BSc Double major in Computer Science and Physics\", \"score\": 0.85216236, \"raw_content\": null}, {\"url\": \"https://www.klover.ai/andrej-karpathy/\", \"title\": \"Andrej Karpathy: Architect of an AI Revolution - Klover.ai\", \"content\": \"Karpathy’s association with OpenAI is also extensive, marked by two distinct tenures. He was a founding member of the artificial intelligence research group, working as a research scientist from 2015 to 2017.1 During this initial period, his research focused on deep learning models, particularly in areas like computer vision, generative modeling, and reinforcement learning.1 He was drawn to OpenAI’s “historically unprecedented model for innovation,” which aimed to ensure that artificial general intelligence benefits all of humanity.31 His early work contributed to the foundational research that would later underpin some of OpenAI’s most famous creations, including the GPT series of language models. After his time at Tesla, Karpathy returned to OpenAI in February 2023.1 He was inspired by [...] From June 2017 to July 2022, Karpathy served as the Senior Director of AI at Tesla, reporting directly to CEO Elon Musk.1 He led the computer vision team responsible for Tesla’s Autopilot system. This multifaceted role encompassed overseeing in-house data labeling operations, neural network training, core scientific research and development, and the deployment of Autopilot features to Tesla’s global fleet of vehicles.1 The primary objective was the advancement of Full Self-Driving (FSD) capabilities, with the ambitious goal of significantly enhancing driver assistance systems and overall vehicle safety.1 Karpathy became a public face for Tesla’s AI efforts, delivering detailed presentations at events like Tesla AI Day in 2021 and Tesla Autonomy Day in 2019.1 These talks offered [...] Andrej Karpathy’s journey in artificial intelligence has solidified his position as one of the most influential and respected figures in the field. His “legend” status is not derived from a single breakthrough but from a rare and potent combination of deep technical innovation, impactful leadership in both pioneering research institutions and industry giants, a profound and effective dedication to AI education, and visionary thought leadership that continues to shape the discourse on AI’s future. His work has consistently been at the vanguard of AI’s most significant advancements, from foundational research in computer vision and natural language processing to the development of cutting-edge systems like Tesla’s Autopilot and contributions to OpenAI’s GPT models.\", \"score\": 0.8377398, \"raw_content\": null}], \"response_time\": 1.14, \"request_id\": \"62573943-33cd-47f2-9e15-3ae9bcf6d5b4\"}', name='tavily_search', id='04c1d851-534a-4f28-98d2-8ea1d8613b94', tool_call_id='call_-7848784315163868241'),\n",
       "  AIMessage(content='\\n检索完毕', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 4393, 'total_tokens': 4397}, 'model_name': 'glm-4', 'finish_reason': 'stop'}, id='lc_run--019ca856-ff02-7e41-9270-d334ca1429b1-0', tool_calls=[], invalid_tool_calls=[]),\n",
       "  AIMessage(content='\\n# Andrej Karpathy：人工智能领域的先驱与教育创新者\\n\\nAndrej Karpathy是一位斯洛伐克裔加拿大计算机科学家，以其在深度学习和计算机视觉领域的开创性工作而闻名。他是Eureka Labs的创始人，该组织专注于利用人工智能技术革新教育领域。Karpathy在人工智能界有着卓越的职业生涯，曾在OpenAI担任创始成员，并在特斯拉领导人工智能团队。\\n\\n## 教育背景与学术生涯\\n\\nKarpathy于2005年至2009年在多伦多大学获得计算机科学与物理学双学士学位，辅修数学。正是在多伦多大学期间，他首次接触深度学习，参加了Geoff Hinton的课程和阅读小组。随后，他在不列颠哥伦比亚大学完成了硕士学位（2011年），研究方向为物理模拟图形。2011年至2015年，他在斯坦福大学攻读计算机科学博士学位，师从李飞飞教授，专注于卷积/循环神经网络及其在计算机视觉、自然语言处理及其交叉领域的应用。\\n\\n在斯坦福期间，Karpathy设计和主讲了该校第一门深度学习课程CS 231n：卷积神经网络视觉识别。这门课程迅速成为斯坦福最受欢迎的课程之一，从2015年的150名学生增长到2017年的750名学生。他还开发了多个JavaScript深度学习库，如ConvNetJS、RecurrentJS等，为Web开发者提供了便捷的深度学习工具。\\n\\n## 职业生涯与主要贡献\\n\\n### OpenAI时期（2015-2017）\\nKarpathy是OpenAI的创始成员之一，担任研究科学家。在OpenAI期间，他的研究重点包括深度学习模型、计算机视觉、生成模型和强化学习。他的早期工作为OpenAI后续著名的GPT系列语言模型奠定了基础。\\n\\n### 特斯拉时期（2017-2022）\\n2017年6月，Karpathy加入特斯拉，担任人工智能高级总监，直接向埃隆·马斯克汇报。他领导了特斯拉Autopilot的计算机视觉团队，负责所有神经网络系统的开发。他的团队涵盖了内部数据标注、神经网络训练和部署等工作，目标是通过人工智能实现完全自动驾驶(FSD)。在特斯拉期间，Karpathy成为公司AI努力的重要公众面孔，在2019年特斯拉自动驾驶日和2021年特斯拉AI日等活动上进行了详细演讲。\\n\\nKarpathy于2022年7月离开特斯拉，开始了一段为期数月的休假。2023年2月，他开始制作YouTube视频，教授如何创建人工神经网络，这些视频受到了广泛关注和欢迎。\\n\\n### 当前工作（2023至今）\\n目前，Karpathy专注于他的新项目Eureka Labs，该组织致力于利用AI技术革新教育。同时，他通过YouTube等平台分享AI知识，教授从零开始构建神经网络等内容，继续对AI教育领域产生深远影响。\\n\\n## 影响与认可\\n\\nKarpathy被《麻省理工科技评论》评为2020年\"35岁以下创新者\"之一。他在学术界和工业界的双重成就使他成为人工智能领域最具影响力和最受尊敬的人物之一。他的工作始终处于人工智能最前沿，从计算机视觉和自然语言处理的基础研究，到特斯拉Autopilot等尖端系统的开发，以及对OpenAI GPT模型的贡献。\\n\\nKarpathy的独特之处在于他结合了深厚的技术创新、在开创性研究机构和行业巨头中的有效领导力、对AI教育的深刻承诺以及塑造AI未来讨论的远见卓识。他的职业生涯展示了如何将学术研究与实际应用相结合，推动人工智能领域的进步，并通过教育使更多人能够理解和参与这一革命性技术。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 729, 'prompt_tokens': 2752, 'total_tokens': 3481}, 'model_name': 'glm-4', 'finish_reason': 'stop'}, id='lc_run--019ca857-05a9-7c61-85dc-c5ed97cb1db6-0', tool_calls=[], invalid_tool_calls=[])]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "94c128cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "写一个关于andrej karthy的介绍\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"questions\": [\n",
      "        \"Who is Andrej Karpathy and what is his background in AI?\",\n",
      "        \"What are Andrej Karpathy's key contributions to the field of deep learning and computer vision?\",\n",
      "        \"What is Andrej Karpathy's current role and recent work at Tesla and OpenAI?\"\n",
      "    ]\n",
      "}\n",
      "```\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (call_-7848784315163868241)\n",
      " Call ID: call_-7848784315163868241\n",
      "  Args:\n",
      "    query: Andrej Karpathy AI deep learning computer vision Tesla OpenAI biography\n",
      "    search_depth: advanced\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"Andrej Karpathy AI deep learning computer vision Tesla OpenAI biography\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.aaespeakers.com/keynote-speakers/andrej-karpathy\", \"title\": \"Andrej Karpathy | Keynote Speaker | AAE Speakers Bureau\", \"content\": \"BOOK ANDREJ KARPATHY\\n\\n PROFILE\\n VIDEO\\n CHECK AVAILABILITY\\n\\n## Andrej Karpathy Biography\\n\\nAndrej Karpathy is a Slovak-Canadian computer scientist who founded the AI+education organization Eureka Labs. He specializes in deep learning and computer vision. He trains deep neural nets on large datasets.\\n\\nHe formerly served as the director of AI and Autopilot Vision at Tesla. He was a founding member of OpenAI.\\n\\nKarpathy was born in Bratislava, Czechoslovakia (now Slovakia) and moved with his family to Toronto when he was 15. He completed his Computer Science and Physics bachelor's degree at University of Toronto in 2009 and completed his master's degree at University of British Columbia in 2011, where he worked on physically-simulated figures. [...] # Andrej Karpathy\\n\\n## Keynote Speaker: Founder at Eureka Labs; Former Director of AI at Tesla & Founding Member of OpenAI; Expert in Deep Learning & Computer Vision; Named MIT Technology Review's Innovators Under 35\\n\\n Travels From:\\n\\n  Stanford, CA, USA\\n Speaking Fee:\\n\\n  Live Event Fee: Contact us for details   \\n   Virtual Event Fee: Contact us for details   \\n   More Fee Info)\\n\\n  ### Fee Range [...] Karpathy is a founding member of the artificial intelligence research group OpenAI, where he worked from 2015 to 2017 as a research scientist. In June 2017 he became Tesla's director of artificial intelligence. Karpathy was named one of MIT Technology Review's Innovators Under 35 for the year 2020. After taking a several months-long sabbatical from Tesla, Karpathy announced he was leaving the company in July 2022. As of February 2023, he makes YouTube videos instructing how to create artificial neural networks.\\n\\n#### Contact a speaker booking agent to check availability on Andrej Karpathy and other top speakers and celebrities.\\n\\nBOOK ANDREJ KARPATHY\\n\\n## Andrej Karpathy Videos\\n\\nLet's reproduce GPT-2\\n\\nNeural Networks: Zero to Hero\\n\\nDeep Dive into LLMs like ChatGPT\\n\\nSee All Videos »;)\", \"score\": 0.9281033, \"raw_content\": null}, {\"url\": \"https://karpathy.ai/\", \"title\": \"Andrej Karpathy\", \"content\": \"2005 - 2009 \\n\\nImage 14\\n\\n BSc at the University of Toronto with a double major in computer science and physics and a minor in math. This is where I first got into deep learning, attending Geoff Hinton's class and reading groups. \\n\\nbio\\n\\nAndrej Karpathy is an AI researcher and founder of Eureka Labs, focused on modernizing education in the age of AI. He previously served as the Director of AI at Tesla and was a founding member of OpenAI. During his PhD at Stanford, he was the architect and lead instructor of the first deep learning course at Stanford (CS231n), which has become one of its most popular classes.\\n\\nfeatured talks\\n\\nImage 15\\n\\nDwarkesh podcast 2025\\n\\nImage 16\\n\\nYC AI Startup School 2025\\n\\nImage 17\\n\\nGPU Mode 2024\\n\\nImage 18\\n\\nNo Priors podcast 2024\\n\\nImage 19 [...] 2017 - 2022 \\n\\nImage 10\\n\\n I was the Director of AI at Tesla, where I led the computer vision team of Tesla Autopilot and (very briefly) Tesla Optimus). My team handled all in-house data labeling, neural network training and deployment on Tesla's custom inference chip. Today, the Autopilot increases the safety and convenience of driving, but the team's goal is to make Full Self-Driving a reality at scale. See Aug 2021 Tesla AI Day for more. \\n\\n 2015 - 2017 \\n\\nImage 11\\n\\n I was a research scientist and a founding member at OpenAI. \\n\\n 2011 - 2015 \\n\\nImage 12 [...] 2011 - 2015 \\n\\nImage 12\\n\\n My PhD was focused on convolutional/recurrent neural networks and their applications in computer vision, natural language processing and their intersection. My adviser was Fei-Fei Li at the Stanford Vision Lab and I also had the pleasure to work with Daphne Koller, Andrew Ng, Sebastian Thrun and Vladlen Koltun along the way during the first year rotation program. \\n\\n I designed and was the primary instructor for the first deep learning class Stanford - CS 231n: Convolutional Neural Networks for Visual Recognition. The class became one of the largest at Stanford and has grown from 150 enrolled in 2015 to 330 students in 2016, and 750 students in 2017.\", \"score\": 0.8703443, \"raw_content\": null}, {\"url\": \"https://brief.bismarckanalysis.com/p/ai-2026-andrej-karpathys-next-big\", \"title\": \"AI 2026: Andrej Karpathy's Next Big Project - Bismarck Brief\", \"content\": \"Andrej Karpathy is a computer scientist, AI researcher, and expert in computer vision who was a founding member of OpenAI and then head of Tesla’s Autopilot driver assistance and self-driving car program from 2017 to 2022, where he was responsible for building the team and technology that today powers Tesla’s autonomous driving capabilities. Self-driving vehicles promise to be one of the most immediate and consequential areas where AI progress will obsolete human labor in the physical world. Whereas Google’s Waymo and other self-driving efforts have attempted to scale up safe autonomous taxis using multiple types of redundant sensors and extensive reference mapping of the environment, Elon Musk has instead pursued a “vision-only” approach focused on achieving self-driving AI software [...] Bismarck Brief\\n\\n# Bismarck Brief\\n\\n# AI 2026: Andrej Karpathy’s Next Big Project\\n\\n### The OpenAI cofounder and former head of Tesla's self-driving division is a skilled engineer and public communicator who is now focused on using AI to improve education and other passion projects.\\n\\nSamo Burja's avatar\\n\\nThis Bismarck Brief will contribute to our exclusive upcoming AI 2026 Bismarck Strategic Report, which will feature in-depth analysis of the state of the artificial intelligence sector and technology, together with a comprehensive profile of key players. Upgrade or subscribe now to receive full access and never miss a report.\", \"score\": 0.8539252, \"raw_content\": null}, {\"url\": \"https://cs.stanford.edu/people/karpathy/\", \"title\": \"Andrej Karpathy Academic Website - Stanford\", \"content\": \"Bio. I am the Sr. Director of AI at Tesla, where I lead the team responsible for all neural networks on the Autopilot. Previously, I was a Research Scientist at OpenAI working on Deep Learning in Computer Vision, Generative Modeling and Reinforcement Learning. I received my PhD from Stanford, where I worked with Fei-Fei Li on Convolutional/Recurrent Neural Network architectures and their applications in Computer Vision, Natural Language Processing and their intersection. Over the course of my PhD I squeezed in two internships at Google where I worked on large-scale feature learning over YouTube videos, and in 2015 I interned at DeepMind on the Deep Reinforcement Learning team. Together with Fei-Fei, I designed and was the primary instructor for a new Stanford class on Convolutional [...] On a side for fun I blog, blog more, and tweet. I developed a number of Deep Learning libraries in Javascript (e.g. ConvNetJS, RecurrentJS, REINFORCEjs, t-sneJS) because I love the web. I am sometimes jokingly referred to as the reference human for ImageNet (post :)). Whenever I can spare the time I maintain arxiv-sanity.com, which lets you search and sort through almost 100,000 Arxiv papers on Machine Learning over the last 6 years.   \\n  \\n Timeline.   \\n 2017-now: Sr. Director of AI at Tesla (article) Neural Networks for the Autopilot   \\n 2016-2017: Research Scientist at OpenAI Deep Learning, Generative Models, Reinforcement Learning   \\n Summer 2015: DeepMind Internship Deep Reinforcement Learning group [...] Summer 2013: Google Research Internship Large-Scale Supervised Deep Learning for Videos   \\n 2011-2015: Stanford Computer Science Ph.D. student Deep Learning, Computer Vision, Natural Language Processing. Adviser: Fei-Fei Li.   \\n Summer 2011: Google Research Internship Large-Scale Unsupervised Deep Learning for Videos   \\n 2009-2011: University of British Columbia: MSc Learning Controllers for Physically-simulated Figures. Adviser: Michiel van de Panne   \\n 2005-2009: University of Toronto: BSc Double major in Computer Science and Physics\", \"score\": 0.85216236, \"raw_content\": null}, {\"url\": \"https://www.klover.ai/andrej-karpathy/\", \"title\": \"Andrej Karpathy: Architect of an AI Revolution - Klover.ai\", \"content\": \"Karpathy’s association with OpenAI is also extensive, marked by two distinct tenures. He was a founding member of the artificial intelligence research group, working as a research scientist from 2015 to 2017.1 During this initial period, his research focused on deep learning models, particularly in areas like computer vision, generative modeling, and reinforcement learning.1 He was drawn to OpenAI’s “historically unprecedented model for innovation,” which aimed to ensure that artificial general intelligence benefits all of humanity.31 His early work contributed to the foundational research that would later underpin some of OpenAI’s most famous creations, including the GPT series of language models. After his time at Tesla, Karpathy returned to OpenAI in February 2023.1 He was inspired by [...] From June 2017 to July 2022, Karpathy served as the Senior Director of AI at Tesla, reporting directly to CEO Elon Musk.1 He led the computer vision team responsible for Tesla’s Autopilot system. This multifaceted role encompassed overseeing in-house data labeling operations, neural network training, core scientific research and development, and the deployment of Autopilot features to Tesla’s global fleet of vehicles.1 The primary objective was the advancement of Full Self-Driving (FSD) capabilities, with the ambitious goal of significantly enhancing driver assistance systems and overall vehicle safety.1 Karpathy became a public face for Tesla’s AI efforts, delivering detailed presentations at events like Tesla AI Day in 2021 and Tesla Autonomy Day in 2019.1 These talks offered [...] Andrej Karpathy’s journey in artificial intelligence has solidified his position as one of the most influential and respected figures in the field. His “legend” status is not derived from a single breakthrough but from a rare and potent combination of deep technical innovation, impactful leadership in both pioneering research institutions and industry giants, a profound and effective dedication to AI education, and visionary thought leadership that continues to shape the discourse on AI’s future. His work has consistently been at the vanguard of AI’s most significant advancements, from foundational research in computer vision and natural language processing to the development of cutting-edge systems like Tesla’s Autopilot and contributions to OpenAI’s GPT models.\", \"score\": 0.8377398, \"raw_content\": null}], \"response_time\": 1.14, \"request_id\": \"62573943-33cd-47f2-9e15-3ae9bcf6d5b4\"}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "\n",
      "检索完毕\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "\n",
      "# Andrej Karpathy：人工智能领域的先驱与教育创新者\n",
      "\n",
      "Andrej Karpathy是一位斯洛伐克裔加拿大计算机科学家，以其在深度学习和计算机视觉领域的开创性工作而闻名。他是Eureka Labs的创始人，该组织专注于利用人工智能技术革新教育领域。Karpathy在人工智能界有着卓越的职业生涯，曾在OpenAI担任创始成员，并在特斯拉领导人工智能团队。\n",
      "\n",
      "## 教育背景与学术生涯\n",
      "\n",
      "Karpathy于2005年至2009年在多伦多大学获得计算机科学与物理学双学士学位，辅修数学。正是在多伦多大学期间，他首次接触深度学习，参加了Geoff Hinton的课程和阅读小组。随后，他在不列颠哥伦比亚大学完成了硕士学位（2011年），研究方向为物理模拟图形。2011年至2015年，他在斯坦福大学攻读计算机科学博士学位，师从李飞飞教授，专注于卷积/循环神经网络及其在计算机视觉、自然语言处理及其交叉领域的应用。\n",
      "\n",
      "在斯坦福期间，Karpathy设计和主讲了该校第一门深度学习课程CS 231n：卷积神经网络视觉识别。这门课程迅速成为斯坦福最受欢迎的课程之一，从2015年的150名学生增长到2017年的750名学生。他还开发了多个JavaScript深度学习库，如ConvNetJS、RecurrentJS等，为Web开发者提供了便捷的深度学习工具。\n",
      "\n",
      "## 职业生涯与主要贡献\n",
      "\n",
      "### OpenAI时期（2015-2017）\n",
      "Karpathy是OpenAI的创始成员之一，担任研究科学家。在OpenAI期间，他的研究重点包括深度学习模型、计算机视觉、生成模型和强化学习。他的早期工作为OpenAI后续著名的GPT系列语言模型奠定了基础。\n",
      "\n",
      "### 特斯拉时期（2017-2022）\n",
      "2017年6月，Karpathy加入特斯拉，担任人工智能高级总监，直接向埃隆·马斯克汇报。他领导了特斯拉Autopilot的计算机视觉团队，负责所有神经网络系统的开发。他的团队涵盖了内部数据标注、神经网络训练和部署等工作，目标是通过人工智能实现完全自动驾驶(FSD)。在特斯拉期间，Karpathy成为公司AI努力的重要公众面孔，在2019年特斯拉自动驾驶日和2021年特斯拉AI日等活动上进行了详细演讲。\n",
      "\n",
      "Karpathy于2022年7月离开特斯拉，开始了一段为期数月的休假。2023年2月，他开始制作YouTube视频，教授如何创建人工神经网络，这些视频受到了广泛关注和欢迎。\n",
      "\n",
      "### 当前工作（2023至今）\n",
      "目前，Karpathy专注于他的新项目Eureka Labs，该组织致力于利用AI技术革新教育。同时，他通过YouTube等平台分享AI知识，教授从零开始构建神经网络等内容，继续对AI教育领域产生深远影响。\n",
      "\n",
      "## 影响与认可\n",
      "\n",
      "Karpathy被《麻省理工科技评论》评为2020年\"35岁以下创新者\"之一。他在学术界和工业界的双重成就使他成为人工智能领域最具影响力和最受尊敬的人物之一。他的工作始终处于人工智能最前沿，从计算机视觉和自然语言处理的基础研究，到特斯拉Autopilot等尖端系统的开发，以及对OpenAI GPT模型的贡献。\n",
      "\n",
      "Karpathy的独特之处在于他结合了深厚的技术创新、在开创性研究机构和行业巨头中的有效领导力、对AI教育的深刻承诺以及塑造AI未来讨论的远见卓识。他的职业生涯展示了如何将学术研究与实际应用相结合，推动人工智能领域的进步，并通过教育使更多人能够理解和参与这一革命性技术。\n"
     ]
    }
   ],
   "source": [
    "for item in output[\"messages\"]:\n",
    "    item.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "67d41451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "帮我写一个 花满楼 的个人生平\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/jwt/api_jwt.py:153: InsecureKeyLengthWarning: The HMAC key is 16 bytes long, which is below the minimum recommended length of 32 bytes for SHA256. See RFC 7518 Section 3.2.\n",
      "  return self._jws.encode(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"questions\": [\n",
      "        \"花满楼的生平经历有哪些重要阶段？\",\n",
      "        \"花满楼的性格特点和价值观是什么？\",\n",
      "        \"花满楼在武侠世界中的主要成就和影响有哪些？\"\n",
      "    ]\n",
      "}\n",
      "```\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "\n",
      "检索完毕\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "\n",
      "# 花满楼个人生平\n",
      "\n",
      "## 家世背景\n",
      "\n",
      "花满楼，别名花七童，是古龙武侠小说《陆小凤传奇》及其衍生作品中的重要虚构人物。他是江南花家第七子，出身于江南地产富豪之家，家境极为富裕。花家在江南地区有着显赫的地位和影响力，这为花满楼提供了优越的成长环境。\n",
      "\n",
      "## 早年经历\n",
      "\n",
      "花满楼七岁时因病（或被铁鞋大盗刺瞎，不同版本有差异）双目失明，从此永远活在黑暗之中。然而，这一不幸的遭遇并没有让他消沉或怨天尤人。相反，他对生命依然充满感激，对人充满爱。自幼失明的经历培养了他超乎常人的感知能力，尤其是听觉和触觉的敏锐度。\n",
      "\n",
      "## 性格特点\n",
      "\n",
      "花满楼是古龙笔下一个极具魅力的人物，他具有以下显著性格特点：\n",
      "\n",
      "1. **温和宽容**：性情温和，待人宽容，从不怨天尤人\n",
      "2. **热爱生活**：对生命有着无与伦比的热爱，终日微笑面对生活\n",
      "3. **和平主义者**：崇尚和平，不喜欢争斗\n",
      "4. **热爱大自然**：欣赏自然之美，感受世界的美好\n",
      "5. **温文儒雅**：举止得体，谈吐优雅\n",
      "6. **知足常乐**：从不因失明而自卑，反而活得比许多健全人更加充实快乐\n",
      "\n",
      "## 武功修为\n",
      "\n",
      "尽管双目失明，花满楼的武功却极为高强，他的独门绝技包括：\n",
      "\n",
      "1. **流云飞袖**：一种精妙的袖法，能在不接触的情况下制敌\n",
      "2. **闻声辨位**：凭借超凡的听觉能力判断周围环境和敌人位置\n",
      "\n",
      "这两种武功使他在江湖上享有盛誉，成为\"江湖一绝\"。他的武功修为不仅体现在招式上，更体现在对武道的理解和对生命的感悟上。\n",
      "\n",
      "## 人际关系\n",
      "\n",
      "花满楼与陆小凤是生死之交，两人性格互补，成为《陆小凤传奇》中最著名的友谊之一。陆小凤风流不羁，而花满楼温文尔雅，两人互相欣赏，互相帮助。\n",
      "\n",
      "此外，花满楼与西门吹雪也建立了深厚的友谊。西门吹雪孤高冷傲，而花满楼平易近人，两人性格截然不同，却都能与陆小凤成为知己，展现了花满楼独特的个人魅力。\n",
      "\n",
      "在2015年电视剧《陆小凤与花满楼》中，花满楼还与上官飞燕发展出一段感情线，两人从敌对到理解，最终互生情愫。\n",
      "\n",
      "## 人生哲学\n",
      "\n",
      "花满楼的人生哲学可以概括为\"感恩\"与\"爱\"。他常说：\"我虽然看不见，但我能听见，能闻到，能感觉到这个世界上的美好。\"他从不为自己的失明而感到遗憾，反而对生命充满感激。\n",
      "\n",
      "花满楼认为：\"生命本身就是一种恩赐，无论它以何种方式呈现。\"这种积极乐观的生活态度使他成为武侠世界中一个独特的存在，也给了读者深刻的启示。\n",
      "\n",
      "## 社会影响与评价\n",
      "\n",
      "花满楼被读者尊称为\"花神\"，他的形象体现了中国传统文化中\"真善美\"的理想人格。他的存在为武侠小说注入了一种新的精神境界——不是通过武功和杀戮来证明自己，而是通过宽容、博爱和智慧来影响他人。\n",
      "\n",
      "古龙通过花满楼这一人物，表达了对生命意义的思考和对理想人格的追求。花满楼的形象超越了传统武侠小说中的人物类型，成为文学史上的经典形象之一。\n",
      "\n",
      "## 影视形象\n",
      "\n",
      "自1976年以来，花满楼这一角色被多位演员诠释，其中包括：\n",
      "\n",
      "- 黄允材（1976年香港电视剧《陆小凤》）\n",
      "- 岳华（1978年香港邵氏电影《绣花大盗》）\n",
      "- 张智尧（2005年央视电视电影系列）\n",
      "- 张晓龙（2015年内地电视剧《陆小凤与花满楼》）\n",
      "\n",
      "每个版本的演绎都各具特色，但都抓住了花满楼温文尔雅、热爱生活的核心特质。\n",
      "\n",
      "## 结语\n",
      "\n",
      "花满楼是古龙武侠世界中的一颗璀璨明珠，他以失明之躯活出了比常人更加精彩的人生。他的故事告诉我们，生命的价值不在于我们拥有什么，而在于我们如何看待和珍惜所拥有的一切。花满楼的形象将继续激励读者去发现生活中的美好，以感恩和爱的心态面对人生的每一个挑战。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "events = app.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"帮我写一个 花满楼 的个人生平\"}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
